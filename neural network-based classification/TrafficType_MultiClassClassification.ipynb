{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f67abab",
   "metadata": {
    "id": "xEJLWvSn7ci1"
   },
   "source": [
    "# TMA01 Question 2 (50 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f3e85",
   "metadata": {
    "id": "oMzx43-f7ci5"
   },
   "source": [
    "**Name**: \\[Enter your name here\\]\n",
    "\n",
    "**PI**: \\[Enter your student ID here\\]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c80a4b3b-c32e-450a-b312-37d0a208ed34",
   "metadata": {},
   "source": [
    "In this question you will attempt to distinguish the type of traffic, given that you've already identified it as being sent over a VPN or not.\n",
    "\n",
    "Each flow is labelled according to the type of traffic.\n",
    "\n",
    "| Traffic | Content |\n",
    "|---------|---------|\n",
    "| Web Browsing | Firefox and Chrome |\n",
    "| Chat | ICQ, AIM, Skype, Facebook and Hangouts | \n",
    "| Streaming | Vimeo and Youtube | \n",
    "| Email | SMPTS, POP3S and IMAPS | \n",
    "| VoIP |Facebook, Skype and Hangouts voice calls (1h duration) | \n",
    "| P2P | uTorrent and Transmission (Bittorrent) |\n",
    "| FT (File Transfer) | Skype, FTPS and SFTP using Filezilla and an external service | \n",
    "\n",
    "Note that there are **two** collections of datasets: one for traffic sent over a VPN, and one for traffic not sent over a VPN. Each collection has training, validation, and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59b649",
   "metadata": {
    "id": "OLi99bkI7ci6",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Completing the question\n",
    "The tasks in this notebook can be addressed using the techniques discussed in the Foundation and Block 1 of the module materials, and the associated notebooks.\n",
    "\n",
    "> **You should be able to complete this question when you have completed the practical activities in Block 1**\n",
    ">\n",
    "> You should look at the notebooks for Block 1 while working through this question. You will find many useful examples in those notebooks which will help you in this assignment.\n",
    "\n",
    "Record all your activity and observations in this notebook. Insert additional notebook cells as required. Remember to run each cell in sequence and to rerun cells if you make any changes in earlier cells. \n",
    "\n",
    "Include Markdown cells (like this one) liberally in your solutions, to describe what you are doing. This will help your tutor give full credit for all you have done, and is invaluable in reminding you what you were doing when you return to the TMA after a few days away.\n",
    "\n",
    "Before you submit your notebook make sure you run all cells in order and check that you get the results you expect. (It is not unknown to receive notebooks which don't work when the cells are run in order.)\n",
    "\n",
    "See the VLE for details of how to submit your completed notebook. You should submit only this notebook file for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7d4f7",
   "metadata": {
    "id": "w0CawPrl7ci6",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-commentate"
    ]
   },
   "source": [
    "## Marks are based on process, not results\n",
    "\n",
    "In this notebook, you will be asked to create, train, and evaluate several neural networks. Training neural networks is inherently a stochastic process, based on the random allocation of initial weights and the shuffled order of training examples. Therefore, your results will differ from results generated by other students, and those generated by the module team and presented in the tutor's marking guide.\n",
    "\n",
    "The marks in this question are awarded solely on your ability to carry out the steps of training and evaluation, not on any particular results you may achieve. **There are no thresholds for accuracy (or any other metric) you must achieve.** You will gain credit for carrying out the tasks specified in this question, including honest evaluations of how the models perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1b941",
   "metadata": {
    "id": "32-3rsFB7ci7",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7248a1b",
   "metadata": {
    "id": "32-3rsFB7ci7"
   },
   "source": [
    "This imports the required libraries and loads the data into training, validation, and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963f0a0",
   "metadata": {
    "id": "hKTWeKcM7ci7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, metrics, Sequential, utils\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8260b-049e-4618-be10-4fd9f7c079ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading and preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30577e2c-fdfc-4410-97f3-8b3372e75e78",
   "metadata": {},
   "source": [
    "This section of the notebook loads the dataset and makes it available for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35301b3c-3387-4130-bfcd-43dbd50aa1c8",
   "metadata": {},
   "source": [
    "First, we define some constants we will use later and define some metrics to use for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651e313-d3f3-4d16-9a02-337a49629a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {i: n.strip() for i, n in enumerate(open('/datasets/cybersecurity/vpn-nonvpn/class_names.txt'))}\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275fd97-72c6-461e-a8d7-a6bd3bb88528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_array = np.array([class_names[i] for i in sorted(class_names)])\n",
    "class_names_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84803424-9c33-4346-ac3a-3851e708506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_cm(cm):\n",
    "    result_table  = '<h3>Confusion matrix</h3>\\n'\n",
    "    result_table += '<table border=1>\\n'\n",
    "    result_table += '<tr><td>&nbsp;</td><td>&nbsp;</td><th colspan=10}>Predicted labels</th></tr>\\n'\n",
    "    result_table += '<tr><td>&nbsp;</td><td>&nbsp;</td>'\n",
    "\n",
    "    for cn in class_names.values():\n",
    "        result_table += f'<td><strong>{cn}</strong></td>'\n",
    "    result_table += '</tr>\\n'\n",
    "\n",
    "    result_table += '<tr>\\n'\n",
    "    result_table += '<th rowspan=11>Actual labels</th>\\n'\n",
    "\n",
    "    for ai, an in class_names.items(): # enumerate(class_names):\n",
    "        result_table += '<tr>\\n'\n",
    "        result_table += f'  <td><strong>{an}</strong></td>\\n'\n",
    "        for pi, pn in class_names.items(): #enumerate(class_names):\n",
    "            result_table += f'  <td>{cm[ai, pi]}</td>\\n'\n",
    "        result_table += '</tr>\\n'\n",
    "    result_table += \"</table>\"\n",
    "    # print(result_table)\n",
    "    display(HTML(result_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d883fc9-c32c-4ea3-a0bd-1ac8d578a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_precision(cmatrix):\n",
    "    s = cmatrix.shape[0]\n",
    "    numerator = tf.reduce_sum(tf.linalg.diag(tf.ones(s)) * cmatrix, axis=0)\n",
    "    denominator = tf.cast(tf.reduce_sum(cmatrix, axis=0), tf.float32)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c566330-c319-4ba4-be21-632e1be06a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_recall(cmatrix):\n",
    "    s = cmatrix.shape[0]\n",
    "    numerator = tf.reduce_sum(tf.linalg.diag(tf.ones(s)) * cmatrix, axis=1)\n",
    "    denominator = tf.cast(tf.reduce_sum(cmatrix, axis=1), tf.float32)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a10c0-da14-4332-9dd5-67fe7f746983",
   "metadata": {},
   "source": [
    "Where to find the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea237b56-d3f9-4506-9584-393346324449",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/datasets/cybersecurity/vpn-nonvpn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cbc1a-21e9-4c74-9f17-a0eb9af8e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vpn_data = tf.data.Dataset.load(os.path.join(base_dir, 'scenario_a2_15s_VPN_train'))\n",
    "train_vpn_data = train_vpn_data.cache()\n",
    "train_vpn_data = train_vpn_data.batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_vpn_data = train_vpn_data.shuffle(1000)\n",
    "train_vpn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b328ff7-1999-41c2-81b6-5534b750fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_vpn_data = tf.data.Dataset.load(os.path.join(base_dir, 'scenario_a2_15s_VPN_validation'))\n",
    "validation_vpn_data = validation_vpn_data.cache()\n",
    "validation_vpn_data = validation_vpn_data.batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_vpn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46fc373-d9f2-485c-b1f3-4f6cc3dfefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vpn_data = tf.data.Dataset.load(os.path.join(base_dir, 'scenario_a2_15s_VPN_test'))\n",
    "test_vpn_data = test_vpn_data.cache()\n",
    "test_vpn_data = test_vpn_data.batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_vpn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d477d-de03-492b-8b7b-45619629fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_vpn_data = tf.data.Dataset.load(os.path.join(base_dir, 'scenario_a2_15s_NO-VPN_train'))\n",
    "train_no_vpn_data = train_no_vpn_data.cache()\n",
    "train_no_vpn_data = train_no_vpn_data.batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_no_vpn_data = train_no_vpn_data.shuffle(1000)\n",
    "train_no_vpn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9710e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_no_vpn_data = tf.data.Dataset.load(os.path.join(base_dir, 'scenario_a2_15s_NO-VPN_validation'))\n",
    "validation_no_vpn_data = validation_no_vpn_data.cache()\n",
    "validation_no_vpn_data = validation_no_vpn_data.batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_no_vpn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa2950",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_no_vpn_data = tf.data.Dataset.load(os.path.join(base_dir, 'scenario_a2_15s_NO-VPN_test'))\n",
    "test_no_vpn_data = test_no_vpn_data.cache()\n",
    "test_no_vpn_data = test_no_vpn_data.batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_no_vpn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (train_vpn_data.element_spec[0].shape[1],)\n",
    "num_classes = train_vpn_data.element_spec[1].shape[1]\n",
    "input_shape, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7db9a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Validation and test labels    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de071a35",
   "metadata": {},
   "source": [
    "Use these for generating confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_vpn_labels = np.array(list(validation_vpn_data.unbatch().map(lambda x, y: y).as_numpy_iterator()))\n",
    "validation_vpn_labels = np.argmax(validation_vpn_labels, axis=1)\n",
    "validation_vpn_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86ea97-d9dd-466b-8cfb-5c4033d6e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_no_vpn_labels = np.array(list(validation_no_vpn_data.unbatch().map(lambda x, y: y).as_numpy_iterator()))\n",
    "validation_no_vpn_labels = np.argmax(validation_no_vpn_labels, axis=1)\n",
    "validation_no_vpn_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687060e1-0213-4a6a-825d-39b0cf3df51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vpn_labels = np.array(list(test_vpn_data.unbatch().map(lambda x, y: y).as_numpy_iterator()))\n",
    "test_vpn_labels = np.argmax(test_vpn_labels, axis=1)\n",
    "test_vpn_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_vpn_labels = np.array(list(test_no_vpn_data.unbatch().map(lambda x, y: y).as_numpy_iterator()))\n",
    "test_no_vpn_labels = np.argmax(test_no_vpn_labels, axis=1)\n",
    "test_no_vpn_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b60f1b",
   "metadata": {
    "id": "PgrXvcqu7cjC",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Part a (14 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0deb25c",
   "metadata": {
    "id": "NA7ZnHrj7cjC",
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "Create a four layer model. The first two layers should have 64 units, the third should have 32 units, and the last should have 7 units (for the seven classes of traffic). Note that you will need an initial `Input` layer with `shape=input_shape`.\n",
    "\n",
    "The first three layers should use `sigmoid` activation. The last layer should use `softmax` activation. \n",
    "\n",
    "The model summary should look like this.\n",
    "\n",
    "```\n",
    "Model: \"sequential\"\n",
    "\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None, 64)             │         1,536 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None, 64)             │         4,160 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None, 32)             │         2,080 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None, 7)              │           231 │\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    "\n",
    " Total params: 8,007 (31.28 KB)\n",
    "\n",
    " Trainable params: 8,007 (31.28 KB)\n",
    "\n",
    " Non-trainable params: 0 (0.00 B)\n",
    "```\n",
    "\n",
    "Store the model in a variable called `model_a`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c63aa",
   "metadata": {
    "id": "WvSNDW4Z7cjC",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "Use the RMSprop optimiser, with its default parameters, and train this model for **200** epochs. Train using the `train_vpn_data` and `validation_vpn_data` defined above, as per the module notebooks. \n",
    "\n",
    "Plot how the accuracy and loss change during training. Comment on your observations of training. \n",
    "\n",
    "Evaluate the model on the test dataset and generate a confusion matrix. Store the confusion matrix in a variable called `cmatrx_a`. Comment on this evaluation and confusion matrix.\n",
    "\n",
    "#### Important\n",
    "This is a multi-class classification task. You must use the `categorical_crossentropy` loss function for training. The final output layer should use the `softmax` activation function.\n",
    "\n",
    "> **Hints**\n",
    "> * When training for many epochs, you may want to pass in the parameter `verbose=0` to `model_a.fit()` to reduce the output verbiage.\n",
    "> * You may want to save the model and the training history so you can reload it in a later session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8505da",
   "metadata": {
    "tags": [
     "style-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "# Use additional cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cade4bc",
   "metadata": {
    "id": "51uTldQvFkkR",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Part b (7 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ac151c",
   "metadata": {
    "id": "w9XOXKgCFZd8",
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "Create another model with the same structure as in part (a). Store this model in a variable called `model_b`. \n",
    "\n",
    "Train this model with the same hyperparameters as in part (a), but now using the `train_no_vpn_data` and `validation_no_vpn_data` datasets. \n",
    "\n",
    "Plot how the accuracy and loss change during training. Comment on your observations of training.\n",
    "\n",
    "Evaluate the model on the test dataset and generate a confusion matrix. Store the confusion matrix in a variable called `cmatrix_b`. Comment on this evaluation and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43770f",
   "metadata": {
    "tags": [
     "style-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "# Use additional cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da562aab",
   "metadata": {
    "id": "96GQZfW-Gy_w",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Part c (8 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4398718",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "You now have two models, one trained on the VPN traffic and one trained on the non-VPN traffic. How good are these models, and how well do these models compare?\n",
    "\n",
    "You can also now replicate the results presented by Draper-Gil _et al._ (2016) figure 3(a)-(d). \n",
    "\n",
    "Using the example below, generate and plot the multi-class precision and multi-class recall scores, based on each of the evaluation of the models created in parts (a) and (b) above. Plot those results in the four subplots of one figure, using the example below for guidance.\n",
    "\n",
    "Comment on your results.\n",
    "\n",
    "Compare your results to those presented by Draper-Gil _et al._ (2016) (paying most attention to the \"15s\" data, as that is what you're using). \n",
    "\n",
    "> Reminder: there are no marks awarded for how well your models do in comparison to those created by Draper-Gil _et al._ This question is about generating results and comparing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721ed47-8abd-42f2-88b2-cde27a392d64",
   "metadata": {
    "tags": [
     "style-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "# Use additional cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62d6fd-6a37-426d-8947-5fb5819bcb17",
   "metadata": {
    "id": "PgrXvcqu7cjC",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Part d (12 marks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b177993-a1f1-400f-a25e-c70418dda3ab",
   "metadata": {
    "id": "NA7ZnHrj7cjC",
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "Create a four layer model with the same structure as parts (a) and (b) above. This new model should use `relu` activation rather than `sigmoid`. (The last layer must still use `softmax` activation.)\n",
    "\n",
    "Store the models in variables called `model_d1` and `model_d2`.\n",
    "\n",
    "Use the SGD optimiser, with its default parameters, and train these models for **300** epochs. \n",
    "\n",
    "Train `model_d1` using the `train_vpn_data` and `validation_vpn_data` defined above. Train `model_d2` using the `train_no_vpn_data` and `validation_no_vpn_data` defined above.\n",
    "\n",
    "Plot how the accuracy and loss change during training. Comment on your observations of training. \n",
    "\n",
    "Evaluate the models on the appropriate test datasets and generate a confusion matrices. Comment on this evaluation and confusion matrices.\n",
    "\n",
    "Compare the performance of the models against those you generated in parts (a) and (b) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106d35c-e512-4a53-8e1c-f59fb9e58232",
   "metadata": {
    "tags": [
     "style-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "# Use additional cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d2603-7f01-4056-8085-6ab5a84aec4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Part e (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc697aa-9229-480a-98a8-6cce78f722af",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "One feature of neural network based models is that they only perform well on data that is similar to what they've been trained on. \n",
    "\n",
    "From the work above, you have two datasets (VPN and non-VPN) and a model trained on each. At first glance, the flows in these datasets should be similar to the other dataset. How well do the models from part (d) work on the dataset it was _not_ trained on?\n",
    "\n",
    "Evaluate each model from part (d) against each test dataset. Compare the results between models and datasets. Comment on what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40632f-eb85-4c85-a94b-7c7b595cba31",
   "metadata": {
    "tags": [
     "style-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "# Use additional cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c0677-3eff-4118-9dee-a6c24014dd94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Part f (6 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a82d2-7e9d-49ef-abac-e3a4cd3ca756",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "You can now address a simplified version of \"scenario B\" from the Draper-Gil _et al._ (2016) paper. This scenario attempts to classify flows by type, when the flows are a mixture of VPN and non-VPN traffic. However, you will only need to classify the flows into the current seven classes, rather than the fourteen in the paper.\n",
    "\n",
    "The cell below combines the `vpn` and `no_vpn` datasets. \n",
    "\n",
    "Use this combined dataset to train another model, with the same structure as in part (d) above. Evaluate the model's performance on the `vpn`, `no_vpn`, and `all` datasets. How does this model compare to the models created in parts (a), (b), and (d)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce5414-7e4d-4ba3-9390-5ac09b45161a",
   "metadata": {
    "tags": [
     "style-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "# Use additional cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138be38-46f0-48d2-a29e-ff45549198c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
